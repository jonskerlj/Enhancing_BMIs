{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyaldata import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = \".\"\n",
    "for (col,filename) in enumerate(os.listdir(path)):\n",
    "    if filename.endswith('.mat'):\n",
    "        fname = os.path.join(path, filename)\n",
    "        #print(fname[:-4])\n",
    "        \n",
    "        # load TrialData .mat file into a DataFrame\n",
    "        df = mat2dataframe(fname, shift_idx_fields=True)\n",
    "        \n",
    "        # combine time bins into longer ones\n",
    "        td = combine_time_bins(df, 3)\n",
    "        \n",
    "        # Remove low-firing neurons\n",
    "        td = remove_low_firing_neurons(td, \"M1_spikes\",  3)\n",
    "        td = remove_low_firing_neurons(td, \"PMd_spikes\", 3)\n",
    "        \n",
    "        # Smooting the signal\n",
    "        td = smooth_signals(td, [\"M1_spikes\", \"PMd_spikes\"], std=0.05)\n",
    "        \n",
    "        # Combine M1 and PMd\n",
    "        td = merge_signals(td, [\"M1_spikes\", \"PMd_spikes\"], \"both_spikes\")\n",
    "        \n",
    "        N = td.shape[0]\n",
    "\n",
    "        for i in range(N):\n",
    "\n",
    "\n",
    "            # get position\n",
    "            pos = td.pos[i]\n",
    "\n",
    "\n",
    "            # get velocities for this trial\n",
    "            vel = td.vel[i]\n",
    "\n",
    "\n",
    "            # get M1 spikes\n",
    "            M1 = td.M1_spikes[i]\n",
    "\n",
    "            # get PMd_spikes\n",
    "            PMd = td.PMd_spikes[i]\n",
    "\n",
    "            # get both\n",
    "            both_spikes = td.both_spikes[i]\n",
    "\n",
    "\n",
    "            if (i == 0):\n",
    "                grouped_pos = pos\n",
    "                grouped_vel = vel\n",
    "\n",
    "                grouped_M1 = M1\n",
    "                grouped_PMd = PMd\n",
    "                grouped_both_spikes = both_spikes\n",
    "            else:\n",
    "                grouped_pos = np.append(grouped_pos, pos, axis=0)\n",
    "                grouped_vel = np.append(grouped_vel, vel, axis=0)\n",
    "                grouped_M1 = np.append(grouped_M1, M1, axis=0)\n",
    "                grouped_PMd = np.append(grouped_PMd, PMd, axis=0)\n",
    "                grouped_both_spikes = np.append(grouped_both_spikes, both_spikes, axis=0);\n",
    "\n",
    "        # Save the data in right format\n",
    "        import pickle\n",
    "\n",
    "        data_folder='data/' #FOLDER YOU WANT TO SAVE THE DATA TO\n",
    "\n",
    "        with open(fname[:-4]+'.pickle','wb') as f:\n",
    "            pickle.dump([grouped_M1, grouped_PMd, grouped_both_spikes, grouped_pos, grouped_vel],f)\n",
    "\n",
    "\n",
    "        #fname = os.path.join(data_dir, \"RS_ind_1.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
